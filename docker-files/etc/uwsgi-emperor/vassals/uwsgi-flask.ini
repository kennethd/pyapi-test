[uwsgi]
socket = /var/run/uwsgi/uwsgi-flask.sock
virtualenv = /app/venv3.11
chdir = /app
plugins = python3
# env vars used by wsgi-file to configure app
env = WSGI_APP_NAME=uwsgi-flask
env = WSGI_APP_PORT=9099
# propagate from docker env
env = WSGI_APP_DEBUG=$(WSGI_APP_DEBUG)
env = WSGI_APP_PROFILER=$(WSGI_APP_PROFILER)
# env var used by profiler to write output
env = WSGI_APP_PROFILER_DATADIR=/app/pyapi-test-data/profile/uwsgi-flask
env = WSGI_APP_PROFILER_SUFFIX=$(WSGI_APP_PROFILER_SUFFIX)
wsgi-file = /app/apps/flask/wsgi.py
callable = application
auto-procname = true
procname-prefix = "uwsgi-flask "
# following from https://www.bloomberg.com/company/stories/configuring-uwsgi-production-deployment/
#
# When uWSGIâ€™s cheaper subsystem is enabled, the master process will spawn
# workers in response to traffic increases and gradually shut workers down as
# traffic subsides
#
# There are various algorithms available to determine how many workers should
# be available at any given moment. The busyness algorithm attempts to always
# have spare workers available, which is useful when anticipating unexpected
# traffic surges.
cheaper-algo = busyness
processes = 16                       ; Maximum number of workers allowed
cheaper = 8                          ; Minimum number of workers allowed
cheaper-initial = 8                  ; Workers created at startup
cheaper-overload = 10                ; Length of a cycle in seconds
cheaper-step = 2                     ; How many workers to spawn at a time
# https://uwsgi.readthedocs.io/en/latest/Cheaper.html#busyness-cheaper-algorithm
cheaper-busyness-multiplier = 10     ; How many cycles to wait before killing workers
cheaper-busyness-min = 25            ; Below this threshold, kill workers (if stable for multiplier cycles)
cheaper-busyness-max = 50            ; Above this threshold, spawn new workers
cheaper-busyness-backlog-alert = 8   ; Spawn emergency workers if more than this many requests are waiting in the queue
cheaper-busyness-backlog-step = 2    ; How many emergegency workers to create if there are too many requests in the queue
